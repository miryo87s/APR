---
format: 
  revealjs:
    theme: ["theme/q-theme.scss"]
    slide-number: c/t
    logo: "unsw-long.png"
    footer: "PhD Seminar"
    code-copy: true
    center-title-slide: false
    include-in-header: heading-meta.html
    code-link: true
    code-overflow: wrap
    highlight-style: a11y
    height: 1080
    width: 1920
    chalkboard: true
    fontsize: 28pt
    linestretch: 1.7
    auto-stretch: false
    html-math-method: mathjax
callout-appearance: simple
callout-icon: false
bibliography: ref.bib
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| echo: false
#| include: false
#| warning: false

librarian::shelf(ggplot2, quiet = T)
```

<h1>Causal Interpretation of Least Square Estimand under Model- and
Design-Based Specification</h1>

<br>

<h2>PhD Seminar</h2>

<hr>

<h3>Fangzhou Yu</h3>

<h3>2024-08-14</h3>

<br>

![](unsw.png){.absolute top="550" left="1400" width="400"}

## The Literature and Motivation

<br>

-   A recent literature has raised concern on OLS/IV estimation of
    treatment effects
    -   Fail to identify a convex average of treatment effects
    -   Negative weights can lead to sign reversal
        <span style="font-size: 70%"> [@small2017instrumental] <span>
-   Negative weights have been observed in various research designs
    -   TWFE specification of staggered DiD <br>
        <span style="font-size: 70%"> [@de2020two;
        @goodman2021difference; @sun2021estimating;
        @borusyak2022revisiting] <span>
    -   OLS with multiple treatments <br> <span style="font-size: 70%">
        [@goldsmith2022contamination] <span>
    -   IV regression with covariates <br> <span style="font-size: 70%">
        [@small2017instrumental; @blandhol2022tsls] <span>

## The Literature and Motivation

<br>

-   Negative weights can arise even in the most basic OLS specification
    $$
    Y_i = \tau_{ols} D_i + X_i \beta + \epsilon_i
    $$ {#eq-ols} for outcome $Y_i$, single treatment $D_i$, and
    covariates $X_i$.
-   @borusyak2024negative show that $\tau$ identifies weighted average
    of treatment effects
    -   Negative weights generally exist if the specification is
        [model-based]{.blue}, <br> i.e. @eq-ols leverages a correct
        model of potential outcomes
    -   No concern if the specification is [design-based]{.blue}, <br>
        i.e. @eq-ols leverages a correct model of treatment

## This Paper

<br>

I show that negative weights are not **necessarily a concern** when
specification is model-based

<br>

-   For design-based specification, the weight is guaranteed to be
    convex
-   For model-based specification, when treatment is **binary**
    -   $\tau_{ols}$ identifies **weighted ATT**
    -   There is potential threat of negative weight
    -   But this is due to the fact that treatment can only take $0$ or
        $1$ and specification is linear
    -   The threat only exists for treated units
    -   There are commonly used specifications that do not suffer from
        negative weight

## This Paper

<br>

I extend to the general case: partially linear regression (PLR) with
continuous treatment

<br>

-   Incorporate binary treatment and OLS as special cases
-   Either specification yields convex weighted average effects
    -   Continuous treatment identifies **weighted average derivative
        effects (WADE)**
    -   Weights depend on the marginal distribution of treatment
-   The weights of PLR is optimally efficient in the class of WADE when
    outcome is homoskedastic
    -   Under standard design-based assumption
    -   Encourage the use of PLR/OLS for estimating causal effect

## More Connection to Literature: Binary Treatment

<br>

[The weighting scheme of OLS/IV with a single
treatment/instrument]{.blue} <br> <span style="font-size: 70%"> e.g.
@angrist1998estimating; @aronow2016does; @sloczynski2022interpreting;
@borusyak2024negative; @imbens1994identification;
@angrist1996identification; @small2017instrumental <span>

-   Similar model- and design-based analysis as @borusyak2024negative
-   Causal interpretation of OLS estimand based on weaker assumptions
-   Extension to IV(LATE) using a weak monotonicity assumptions
    introduced by @small2017instrumental

[Overlap-weighted Inverse Propensity Weighting (IPW)]{.blue} <br>
<span style="font-size: 70%"> @crump2006moving; @li2018balancing <span>

-   Design-based OLS is shown to be equivalent to overlap-weighted IPW

## More Connection to Literature: Continuous Treatment

[Identification of continuous treatment]{.blue} <br>
<span style="font-size: 70%"> @rothenhausler2019incremental;
@callaway2024difference; @borusyak2024negative <span>

-   I show continuous treatment generally identifies derivative effects
    introduced by @rothenhausler2019incremental

[Nonparametric Index Model]{.blue} <br> <span style="font-size: 70%">
e.g. @robinson1988root; @powell1989semiparametric;
@hardle1989investigating <span>

-   First to connect PLR/Index Model to causal inference
-   Identification based on Riesz Representation theorem

[Efficient WADE]{.blue} <br>

-   The efficiency result extends the efficiency bound for binary
    treatment established by @crump2006moving and @li2018balancing

[Estimation of PLR]{.blue} <br> <span style="font-size: 70%">
@robins1994estimation; @chernozhukov2018double <span>

## OLS with Binary Treatment

<br>

-   Potential outcomes: $Y_i(1)$ and $Y_i(0)$
-   Observed outcome: $Y_i = D_iY_i(1) + (1 - D_i)Y_i(0)$
-   Rearrange to get $$
    Y_i = (Y_i(1) - Y_i(0))D_i + Y_i(0) = \tau_i D_i + Y_i(0)
    $$ where $\tau_i = Y_i(1) - Y_i(0)$ is the individual treatment
    effect
-   Consider OLS estimation of $$
    Y_i = \tau_{ols} D_i + X_i \beta + \epsilon_i
    $$

Let $\tilde{D}_i$ be the residual of the population projection of $D_i$
on $X_i$. By Frish-Waugh-Lovell theorem, $$
\tau_{ols} = \frac{\mathbb{E}[\tilde{D}_iY_i]}{\mathbb{E}[\tilde{D}_iD_i]} = \frac{\mathbb{E}[\tau_i\tilde{D}_iD_i] + \mathbb{E}[\tilde{D}_iY_i(0)]}{\mathbb{E}[\tilde{D}_iD_i]}. 
$$ {#eq-tau}

## OLS with Binary Treatment

<br>

Model-based specification:

$$
\mathbb{E}[Y_i(0)|D_i, X_i] = X_i\eta.
$$ {#eq-model}

**Example:** parallel trend assumptions. $X_i$ includes time and unit
dummies with $i$ indexing a pair of time and unit.

<br>

Design-based specification:

$$
\mathbb{E}[D_i|Y_i(0), Y_i(1), X_i] = X_i\gamma.
$$ {#eq-design}

**Example:** $D_i$ is the eligibility for a program which is determined
by some features $X_i$. $\tau_i$ is intention-to-treat effect.

<br>

-   Both can be seen as a combination of **conditional mean-independence
    and linearity**
-   Both are weaker than what is usually assumed in empirical research

## OLS Model-Based Weight

<br>

-   Under either specification, $\mathbb{E}[\tilde{D}_iY_i(0)] = 0$ by
    mean-independence

<br>

-   Under model-based specification, $$
    \tau_{ols} = \frac{\mathbb{E}[\lambda_i\tau_i]}{\mathbb{E}[\lambda_i]}, \quad \lambda_i = \tilde{D}_i D_i
    $$
-   $\lambda_i = 0$ when $D_i = 0$, so $\tau_{ols}$ is **weighted ATT**
-   $\lambda_i = 0$ cannot preclude negative values
    -   Negative when $D_i = 1$ and $\tilde{D}_i < 0$, i.e. the
        projection of $D_i$ on $X_i$ exceeds unit value
-   But @borusyak2024negative overstated the concern
    -   "... (model-based) weighting scheme is not convex. This is
        because $\tilde{D}_i$ necessarily takes on both positive and
        negative values, since $\mathbb{E}[\tilde{D}_i] = 0$"

## OLS Design-Based Weight

<br>

-   Under design-based specification
-   By the law of total expectation,

$$
\mathbb{E}[\tau_i\tilde{D}_iD_i] = \mathbb{E}[\mathbb{E}[\tilde{D}_iD_i|Y_i(0), Y_i(1), X_i]\tau_i]
$$

-   Therefore, we have

$$
\tau_{ols} = \frac{\mathbb{E}[\omega_i\tau_i]}{\mathbb{E}[\omega_i]}, \quad \omega_i = Var(D_i | Y_i(0), Y_i(1), X_i)
$$

-   $\omega_i$ is guaranteed to be convex because
    $Var(D_i | Y_i(0), Y_i(1), X_i) \geqslant 0$

## Special Model-Based Assumptions

Special cases where model-based assumptions can guarantee convex weights

<br>

[Special Case 1: Saturated $X_i$]{.blue}

-   This case was studied in @angrist1998estimating
-   A common example of saturated $X_i$ is One-Way Fixed Effect

$$
Y_i = \beta_s + \tau_{owfe} D_i + \epsilon_i
$$

-   Let $n_{1s} = \sum_{i \in s}D_i$, $n_{0s} = \sum_{i \in s}1 - D_i$
-   Let $\bar{Y}_{ds}$ be the sample mean of $Y_i$ in the treatment and
    control group for $d = 1, 0$ in stratum $s$

$$
\tau_{owfe} = \frac{\mathbb{E}[\lambda_{owfe, s}\tau_s]}{\mathbb{E}[\lambda_{owfe, s}]}, \quad \lambda_s = \frac{n_{1s}n_{0s}}{n_{1s} + n_{0s}}, \ \tau_s = \bar{Y}_{1s} - \bar{Y}_{0s}
$$

## Special Model-Based Assumptions

<br>

[Special Case 2: Full Interaction Regression]{.blue}

-   Consider an extra assumption
    $\mathbb{E}[\tau_i | D_i, X_i] = X_i\xi$ and the flexible
    specification

$$
Y_i = \tau_{ob}D_i + (X_i - \bar{X})\beta + D_i(X_i - \bar{X})\xi + \epsilon_i
$$

-   $\tau_{ob}$ identifies the ATE
-   This method is equivalent to regressing $Y_i$ on $X_i$ using
    treatment group and control group separately
-   Also equivalent to Oaxaca-Blinder method [@oaxaca1973male;
    @blinder1973wage]
-   @kline2011oaxaca showed $\tau_{ob}$ is equivalent to IPW with a
    linear model for the conditional odds of being treated

## Special Model-Based Assumptions

<br>

[Special Case 3: Canonical DiD]{.blue}

-   Canonical DiD refers to the TWFE model of $2 \times 2$ DiD

$$
Y_{it} = \beta_i + \gamma_t + \tau_{twfe} D_{it} + \epsilon_{it}
$$

-   Parallel trend assumption: $Y_{it}(0)$ is a linear function of
    $\beta_i$ and $\gamma_t$
-   Assume balanced panel data and proportion of treatment group is $p$

$$
\tilde{D}_{it} = D_{it} - \bar{D}_i - \bar{D}_t + \bar{D}
$$

-   $\bar{D}_i$ is mean over time, $\bar{D}_t$ is mean over group, and
    $\bar{D}$ is total mean

## Special Model-Based Assumptions

<br>

[Special Case 3: Canonical DiD cont'd]{.blue}

![](fig/tbl1.png){fig-align="center" width="40%"}

-   $\tilde{D}_i$ is negative for treated in pre-period, or control in
    post-period
-   $D_{it} = 1$ for treated in post-period
-   $\lambda_{it} = (1-p)/2$ for all treated in post-period and $0$
    otherwise. Therefore, $\tau_{twfe}$ is ATT

## Stronger Design-Based Assumption

Stronger design-based assumption is not necessary for convex weights,
but can connect between OLS and IPW

<br>

::: callout-warning
## Assumption 1 (Linear Propensity)

$$
e(x) = \mathbb{E}[D_i | X_i = x] = X_i\delta
$$ where $e(x)$ is the propensity score of treatment.
:::

::: callout-warning
## Assumption 2 (Unconfoundedness and Overlap)

1.  Unconfoundedness: $D_i \perp (Y_i(0), Y_i(1)) | X_i$ .
2.  Overlap:
    $\exists \ \xi > 0, \ \text{s.t.} \ \xi \leqslant e(x) \leqslant 1 - \xi$
    .
:::

## Stronger Design-Based Assumption

::: panel-tabset
### Proposition

::: {#prp-wipw .callout-note}
## Proposition 1 (Equivalence of OLS Estimand and Overlap Weighted IPW)

Under Assumption 1 
$$
\tau_{ols} = \tau_{overlap}
$$ where $\tau_{overlap}$ is the estimand of overlap-weighted IPW 
$$
\tau_{overlap} = \mathbb{E}\left[\frac{e(X_i)(1 - e(X_i))}{\mathbb{E}[e(X_i)(1 - e(X_i))]} \cdot \left(\frac{Y_iD_i}{e(X_i)} - \frac{Y_i(1 - D_i)}{1 - e(X_i)}\right)\right] .
$$

Assumption 2 further yields the identification of overlap-weighted ATE
(@li2018balancing): 
$$
\tau_{ols} = \mathbb{E}\left[\frac{e(X_i)(1 - e(X_i))}{\mathbb{E}[e(X_i)(1 - e(X_i))]} \cdot \tau_i\right] .
$$
:::

### Proof

By the projection or the Frisch-Waugh-Lovell theorem, we have $$
\tau_{ols} = \frac{\mathbb{E}[Y_i\tilde{D}_i]}{\mathbb{E}[\tilde{D}_i^2]}
$$ where $\tilde{D}_i = D_i - X_i\beta_e$ with
$\beta_e = \mathbb{E}[X'X]^{-1}\mathbb{E}[X'D]$. Then we have
$$\begin{aligned}
\tau_{ols} &= \frac{\mathbb{E}[Y_i(D_i - e(X_i))]}{\mathbb{E}[(D_i - e(X_i))^2]} \\
&= \frac{\mathbb{E}[Y_i(D_i - e(X_i))]}{\mathbb{E}[e(X_i)(1 - e(X_i))]} \\
&= \mathbb{E}\left[\frac{e(X_i)(1 - e(X_i))}{\mathbb{E}[e(X_i)(1 - e(X_i))]} \frac{Y_i(D_i - e(X_i))}{e(X_i)(1 - e(X_i))}\right]  = \tau_{overlap}
\end{aligned}$$

Identification of $\tau_{overlap}$ under Assumption 2 follows standard
proof of IPW.
:::

## Extension to IV

<br>

Further follow @small2017instrumental, assume

::: callout-warning
## Assumption 3 (Stochastic First-Stage Monotonicity)

$$
Pr(D_i = 1 | Y_i(0), Y_i(1), Z_i = 1, X_i = x) \geqslant Pr(D_i = 1 | Y_i(0), Y_i(1), Z_i = 0, X_i = x) \ \text{for all} \ x. 
$$
:::

Model-based specification: $\mathbb{E}[Y_i(0)|Z_i, X_i] = X_i\eta$

$$
\tau_{iv} = \frac{\mathbb{E}[\lambda_i\tau_i]}{\mathbb{E}[\lambda_i]}, \quad \text{where} \ \lambda_i = \tilde{Z_i}D_i. 
$$

Design-based specification:
$\mathbb{E}[Z_i|Y_i(0), Y_i(1), X_i] = X_i\gamma$

$$
\tau_{iv} = \frac{\mathbb{E}[\omega_i\tau_i]}{\mathbb{E}[\omega_i]}, \quad \text{where} \ \omega_i = Cov(\tilde{Z}_i, Pr(D_i = 1 | Y_i(0), Y_i(1), Z_i, X_i)). 
$$

## Summary of OLS with Binary Treatment

<br>

Design-based specification:

-   Ensures convex weight
-   Equivalent to overlap-weighted IPW under stronger assumptions

Model-based specification:

-   Carries a potential risk of negative weights
-   Due to the projection of $D_i$ on $X_i$ exceeding unit value
-   There are special cases where negative weights are no concern

<br>

Next, extend to partially linear regression with continuous treatment

## Set Up

<br>

-   Suppose we observe iid observations of $(Y_i, D_i, X_i)$ with
    unknown distribution $P$
-   $Y_i \in \mathbb{R}$, $D_i \in \mathbb{R}$, $X_i \in \mathbb{R}^p$
-   Let $\mathcal{H}$ be a Hilbert space of functions
    $l: \mathbb{R}^{p+1} \mapsto \mathbb{R}$ equipped with inner-product
    $\langle l, h \rangle = \mathbb{E}[l(D_i, X_i)h(D_i, X_i)]$ and norm
    $\Vert l \Vert = \langle l, l \rangle^{1/2}$
-   Let $\mu(D_i, X_i) = \mathbb{E}[Y_i | D_i, X_i]$. Assume
    $\mu \in \mathcal{H}$
-   Consider partially linear regression

$$
Y_i = \tau_{ls}D_i + g(X_i) + \epsilon_i.
$$

-   The least square estimand $\tau_{ls}$ and $g$ are defined by

$$
(\tau_{ls}, g) = \arg \min_{\tau \in \mathbb{R}, g^* \in \mathcal{G}} \mathbb{E}\left[(Y_i - \tau D_i - g^*(X_i))^2\right]
$$ where $\mathcal{G}$ is some linear space of functions

## Set Up

<br>

The causal effect of continuous treatment is still an active research
topic

@callaway2024difference & @borusyak2024negative:

-   Restrict treatment value $D_i \neq 0$
-   Define causal effect as average causal derivative
    $\partial\mathbb{E}[Y_i(d)]/\partial d$ or the direct derivative
    $\partial Y_i(d)/ \partial d$
-   Limited discussion on general identification

I follow @rothenhausler2019incremental:

-   First define incremental effect:

$$
\tau^\nu = \frac{\mathbb{E}[Y_i(d + \nu)] - \mathbb{E}[Y_i(d)]}{\nu}
$$

-   Define the **average derivative effect (ADE)**
    $\tau^0 = \lim_{\nu \rightarrow 0} \tau^\nu$

## Set Up

<br>

-   Let $\mu'(D_i, X_i)$ be the partial derivative with respect to $D_i$
-   Will show $\mu'(D_i, X_i)$ identifies $\tau^0$ under model- and
    design-based specification
-   Target is to show $\tau_{ls}$ is WADE
    $\tau_{wade} = \mathbb{E}[w(D_i, X_i)\mu'(D_i, X_i)]$ for some
    weight $w(d, x)$

<br>

Riesz Representation Theorem:

There exists a unique Riesz Representer $\alpha_w \in \mathcal{H}$ such
that $\tau_{wade} = \mathbb{E}[\alpha_w(D_i, X_i)\mu(D_i, X_i)]$ and
hence $\mathbb{E}[\alpha_w(D_i, X_i)Y_i]$

-   @powell1989semiparametric derived Riesz Representation of a given
    index model
-   In my context, Riesz Representation is given by PLR
-   Then the target is to backtrack $w(D_i, X_i)$

## Set Up

<br>

-   Need to restrict to normalized weights such that
    $\mathbb{E}[w(D_i, X_i)] = 1$
-   Allow for negative weights
-   Instead of restricting the weights, consider $\alpha_w$ in the set

$$
\mathcal{A} = \{\alpha \in \mathcal{H} | \mathbb{E}[\alpha(D_i, X_i)D_i] = 1, \mathbb{E}[\alpha(D_i, X_i) | X_i] = 0\}.
$$

-   First condition ensures normalized weight
-   Second is the property of Riesz Representer

## PLR with Continuous Treatment

<br>

::: callout-warning
## Assumption 4 (Model-Based Specification)

Let $\mu^d(X_i) = \mathbb{E}[Y_i(d) |X_i]$.

$$
\mathbb{E}[Y_i(d) | D_i, X_i] = \mu^d(X_i), \ \text{and} \ \mu^d \in \mathcal{G} \ \text{for all} \ d.
$$
:::

::: callout-warning
## Assumption 5 (Design-Based Specification)

Let $q(X_i) = \mathbb{E}[D_i |X_i]$.

$$
\mathbb{E}[D_i | Y_i(d), X_i] = q(X_i) \ \text{for all} \ d, \ \text{and} \ q \in \mathcal{G}.
$$
:::

## PLR with Continuous Treatment

<br>

::: callout-tip
## Theorem 1 (Weighting Scheme in LS Estimand)

Under Assumption 4, 
$$
\tau_{ls} = \mathbb{E}\left[\lambda(D_i, X_i)\mu'(D_i, X_i)\right], \text{where} \ \lambda(d, x) = - \frac{Cov(\tilde{D}_i, \mathbb{I}(D_i \leqslant d) | X_i = x)}{f(d|x)\mathbb{E}[\tilde{D}_i D_i]}
$$

Under Assumption 5, 
$$
\tau_{ls} = \mathbb{E}\left[\omega(D_i, X_i)\mu'(D_i, X_i)\right], \text{where} \ \omega(d, x) = - \frac{Cov(\tilde{D}_i, \mathbb{I}(D_i \leqslant d) | X_i = x)}{f(d|x)\mathbb{E}[Var(D_i | Y_i(\cdot), X_i)]}
$$
:::

$\tilde{D}_i$ is increasing in $D_i$, $\mathbb{I}(D_i \leqslant d)$ is
non-increasing in $D_i$,
$-Cov(\tilde{D}_i, \mathbb{I}(D_i \leqslant d) | X_i = x) \geqslant$ is
non-negative

Either specification yields convex weight

## PLR with Continuous Treatment {.scrollable}

Sketch of proof:

1.  Show $\mu'(D_i, X_i)$ identifies $\tau^0$ under either Assumption 4
    or 5

By conditional mean-independence of $Y_i(d)$ and $D_i$ 
$$
\mathbb{E}[Y_i(d + \nu) - Y_i(d) | D_i = d, X_i] = \mathbb{E}[Y_i(d + \nu) | D_i = d + \nu, X_i] - \mathbb{E}[Y_i(d) | D_i = d, X_i]
$$ 
$\text{LHS} = \mathbb{E}[Y_i'(d)|D_i = d, X_i]$, which equals
$\tau^0$ by dominated convergence

$\text{RHS} = (\partial/\partial d) \mathbb{E}[Y_i(d) | D_i = d, X_i] = (\partial/\partial d) \mathbb{E}[Y_i| D_i = d, X_i] = \mu'(D_i, X_i)$
by the fact that $Y_i(d) = Y_i$ when $D_i = d$.

2.  Extend @powell1989semiparametric to WADE and solve for $w(D_i, X_i)$

Under regularity conditions, for a WADE
$\mathbb{E}[w(D_i, X_i)\mu'(D_i, X_i)]$, the corresponding Riesz
Representer is 
$$
\alpha_w(d, x) = - \frac{\partial w(d, x)}{\partial d} - w(d, x) \cdot \frac{\partial \log f(d|x) }{\partial d}
$$

Derivation uses integration by parts. Then solve
$\mathbb{E}[\alpha_w(D_i, X_i) | X_i] = 0$ as an ordinary differential
equation for $w(D_i, X_i)$ 
$$
w(d, z) = \frac{-1}{f(d|x)}\int_{\underline{d}}^{\bar{d}}\alpha_w(d^*, x)\mathbb{I}(d^* \leqslant d)f(d^*|x) \mathrm{d}d^* 
$$

3.  Plug in
    $\alpha_w(D_i, X_i) = \tilde{D}_i/\mathbb{E}[\tilde{D}_iD_i]$ to get
    weight for $\tau_{ls}$ and evaluate under Assumption 4 and 5.

## PLR with Continuous Treatment

<br>

-   LS estimand identifies WADE with convex weight under either
    specification
-   The weight depends on the conditional density $f(D_i|X_i)$
    -   Design-based specification adds interpretability on the weight
    -   Further assume parametric $f(D_i|X_i)$ can simplify the weight

<br>

-   The set up incorporates binary treatment

When $D_i \in \{0, 1\}$, $\mu(1, X_i) - \mu(0, X_i)$ identifies
treatment effect under model- and design-based specifications.

Theorem 1 can be obtained by letting
$w(x) = \mathbb{E}[\alpha_w(D_i, X_i)D_i | X_i = x]$ and
$\mathbb{E}[w(X_i)(\mu(1, X_i) - \mu(0, X_i)]$ be the WATE

## Design-Based LS is Optimally Efficient

<br>

::: callout-tip
## Theorem 2 (Least Square Estimand is Optimal WADE)

Suppose that $Y_i$ is homoskedastic, i.e.
$Var(Y_i | D_i, X_i) = \sigma^2$ is a constant and
$D_i \perp Y_i(d) | X_i$ for all $d$. Then the optimally efficient WADE
is $\tau_{ls}$.
:::

-   Encourages the use of PLR for estimating causal effects
-   Incorporates the efficiency result for binary treatment
    -   Theorem 5.4 in @crump2006moving; Theorem 2 in @li2018balancing

## Design-Based LS is Optimally Efficient {.scrollable}

Sketch of proof:

Suppose there is an efficient estimator $\hat\tau_{wade}$. Then it
follows 
$$
\sqrt{n}(\hat\tau_{wade} - \tau_{wade}) = \frac{1}{\sqrt{n}}\sum_{i=1}^n \phi(Y_i, D_i, X_i) + o_p(1)
$$ 
where $\phi(Y_i, D_i, X_i)$ is the influence function of
$\tau_{wade}$ which contains $\alpha_w$. Thus, 
$$
\sqrt{n}(\hat\tau_{wade} - \tau_{wade}) \xrightarrow{d} N(0, V), \ \text{where} \ V = Var(\phi(Y_i, D_i, X_i)).
$$

The efficiency bound is obtained by minimizing $V$ with respect to
$\alpha_w$, subject to the constrain $\alpha_w \in \mathcal{A}$. 
$$
\alpha(d, x) = \frac{\lambda(d - \tilde{e}(x))}{\sigma^2(d, x)}.
$$ 
where 
$$
\tilde{e}(x) = \frac{\mathbb{E}[D_i / \sigma^2(D_i, X_i) | X_i = x]}{\mathbb{E}[1 / \sigma^2(D_i, X_i) | X_i = x]}
$$ 
and 
$$
\lambda = \mathbb{E}\left[\frac{D_i - \tilde{e}(X_i)D_i}{\sigma^2(D_i, X_i)}\right]^{-1}.
$$

If $\sigma^2(D_i, X_i) = \sigma^2$, the optimal WADE reduces to
$\tau_{ls}$ under unconfoundedness.

For $D_i \in \{0, 1\}$, 
$$
\tilde{e}(x) = \frac{e(x)\sigma^2(0, x)}{e(x)\sigma^2(0, x) + (1 - e(x))\sigma^2(1, x)}
$$ 
and hence, the optimal WATE is 
$$
\mathbb{E}\left[\frac{\tilde{w}(x)}{\mathbb{E}[\tilde{w}(X_i)]}\frac{(D_i - e(x))Y_i}{e(x)(1 - e(x))}\right], \ \text{where} \ \tilde{w}(x) = \left(\frac{\sigma^2(1, x)}{e(x)} + \frac{\sigma^2(0, x)}{1 - e(x)}\right)^{-1}
$$

## Estimation of PLR

-   Follow the Estimating Equation approach
-   Let $\rho(x) = \mathbb{E}[Y_i | X_i = x]$. Derive the influence
    function of $\tau_{ls}$

$$
\phi_{ls}(Y_i, D_i, X_i) = \frac{D_i - e(X_i)}{\mathbb{E}[(D_i - e(X_i))^2]}(Y_i - \rho(X_i) - \tau_{ls}(D_i - e(X_i)))
$$

-   Set the sample mean of $\phi_{ls}$ to zero and solve for $\tau_{ls}$

$$
\hat\tau_{ls} = \frac{\sum_{i=1}^n(D_i - \hat{e}(X_i))(Y_i - \hat\rho(X_i))}{\sum_{i=1}^n(D_i - \hat{e}(X_i))^2}
$$

-   $\hat\tau_{ls}$ has been considered in the literature. The
    difficulty is in dealing with plug-in bias from $\hat{e}$ and
    $\hat\rho$
-   Traditional routine is to assume Donsker condition on $\hat{e}$ and
    $\hat\rho$ [@robins1994estimation]
    -   But usually fail to hold with machine learning methods
-   Modern approach is to use cross-fitting [@chernozhukov2018double]

## Estimation of PLR

::: callout-tip
## Proposition 2

Assume that the following conditions hold:

a.  $\Vert e - \hat{e} \Vert = o_P(n^{-a/4})$ and
    $\Vert \rho - \hat{\rho} \Vert = o_P(n^{-b/4})$ where
    $a \geqslant 1, \ b\geqslant 0$ and $a + b \geqslant 2$.
b.  $n^{-1}\sum_{i = 1}^n(D_i - \hat{e}(X_i)) > 0$ and
    $\mathbb{E}[D_i - e(X_i)] > 0$.
c.  There exists a constant $0 < C < \infty$ such that
    $Var(D_i | X_i) < C$ and $Var(Y_i | X_i) < C$.

And assume that at least one of $d$ or $e$ holds:

d.  (Donsker condition) The quantities
    $(D_i - \hat{e}(X_i))(Y_i - \hat\rho(X_i))$ and
    $(D_i - \hat{e}(X_i))^2$ fall within a P-Donsker class with
    probability approaching $1$.
e.  (Cross-fitting) The sample used to estimate $\hat{e}(x)$ and
    $\hat{\rho}(x)$ is independent of the sample used to construct
    $\hat\tau_{ls}$.

Then, $\hat\tau_{ls}$ is a regular asymptotically linear estimator of
$\tau_{ls}$ with influence function $\phi_{ls}$. Hence,
$\sqrt{n}(\hat\tau_{ls} - \tau_{ls}) \xrightarrow{d} N(0, V)$ and
$V = Var(\phi_{ls}(Y_i, D_i, X_i))$.
:::

## Estimation of PLR {.scrollable}

Sketch of proof:

$$
\hat\tau_{ls} = \frac{\sum_{i=1}^n(D_i - \hat{e}(X_i))(Y_i - \hat\rho(X_i))}{\sum_{i=1}^n(D_i - \hat{e}(X_i))^2} = \frac{\hat\gamma}{\hat\eta}
$$

The strategy is to show that $\hat\gamma$ and $\hat\eta$ are regular
asymptotically linear estimators and then the desired result follows
from Slutsky's theorem.

Note $\hat\eta$ can be seen as a special case of $\hat\gamma$ with $Y_i$
= $D_i$.

For $\hat\gamma$, we have the empirical process decomposition
$$\begin{aligned}
\hat\gamma - \gamma &= (P_n - P)\phi_\gamma(W_i; P) + E_n + R_n \\
E_n &= (P_n - P)[\phi_\gamma(W_i; \hat{P}) - \phi_\gamma(W_i; P)] \\
R_n &= \gamma(\hat{P}) - \gamma(P) + P[\hat\phi_\gamma(W_i; \hat{P})].
\end{aligned}$$

The first term is well-behaved sample mean of influence function.

By Assumption $a$ and Holder's inequality, the empirical process term
$E_n$ is $o_P(n^{-1/2})$ under the Donsker condition and Lemma 19.24 of
@van1998functional, or under cross-fitting condition and Lemma 2 of
@kennedy2020sharp.

$R_n = \mathbb{E}[(\rho(X_i) - \hat\rho(X_i))(e(X_i) - \hat{e}(X_i))]$.
By Cauchy-Schwarz inequality and Assumption $a$, $R_n$ is
$o_P(n^{-1/2})$.

## Application

<br>

-   NSW-CPS data constructed by @lalonde1986evaluating
-   $Y_i$ is post-treatment earnings, $D_i$ is binary treatment of
    joining NSW training
-   $X_i$ are demographics and pre-treatment earnings
-   Treatment group from the experiment of NSW job training program
-   Control group from the CPS data
-   Target is WATE of job training on earnings

<br>

-   Four sets of covariates, same as those in @angrist2009mostly
-   All four specifications can be regarded as model- or design-based

## Application

<br>

-   Compare various estimators

|                          | Estimators                                                                                |
|------------------|------------------------------------------------------|
| $\hat\tau_{ols}$         | OLS estimator                                                                             |
| $\hat\tau_{ls, logit}$   | Design-based PLR estimator, regress $Y_i$ on $D_i$ and logistic estimator $\hat{e}(X_i)$  |
| $\hat\tau_{ipw}$         | Hajek-type IPW estimator of ATE                                                           |
| $\hat\tau_{ls, cf}$      | PLR estimator with $\hat{e}$ and $\hat\rho$ estimated by random forest with cross-fitting |
| $\hat\tau_{ls, donsker}$ | Same as above but without cross-fitting                                                   |

## Application

![](fig/tbl2alt.png){fig-align="center" width="32%"}

## Application

<br>

::: {layout-ncol="2"}
![](fig/fig1.png)

![](fig/fig2.png)
:::

## Application

<br>

The Projection of $D_i$ on $X_i$ (Earnings in 1974)

![](fig/Dfit.png){fig-align="center"}

## Conclusion

<br>

-   This paper explores the role of least square estimands in causal inference
-   OLS/PLR Identifies WADE(WATE) with continuous(binary) treatment and is optimally efficient
-   The weights convey different causal interpretations under model- and design-based specifications

<br>

Final notes:

-   I study the case of single treatment. Negative weights arise in the case of multiple treatments even under design-based specification [@goldsmith2022contamination]
-   Heterogeneity in treatment effects is a key component in the result
    -   Deviation from identifying the ATE is essentially due to model misspecification
    -   If treatment effect is homogeneous, least squares estimands are correctly specified and identify the ATE

## References {visibility="uncounted"}
